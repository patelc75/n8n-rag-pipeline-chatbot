%% The layout only looks good in Notion's Mermaid editor
graph TB
    subgraph "Input Processing"
        A[User Query] --> B[Prompt Engineering]
        B --> C[Structured Prompts]
        C --> D[LLM - Granite,OpenAI Gov, etc]:::yellow
    end

    subgraph RP[RAG Pipeline]
        A --> E[Query Preprocessing]
        E --> G[Similarity Search]
        G --> H[Retrieved Context]
        H --> HA["**Re-rank responses** (automated by model, inspect manually)"]:::yellow
        HA --> D
    end

    subgraph "LLM Core"
        D --> I[Token Generation]
        I --> J[Initial Response]
    end

    subgraph "Evaluation Methods"
        J --> K{Evaluation}
        K --> L["**Procedural Eval** (Exact Match, ROUGE)"]:::green
        K --> M[Semantic Similarity]:::green
        K --> O[Human Feedback - RLHF]:::green
        K --> P[Model-Based Eval - LLM judge]:::green

    end

    subgraph "Improvement Techniques"
        O --> Q[RLHF Process]
        Q --> R[Reward Model]
        R --> S[PPO Training]
        S --> T[âŒ Fine-tuned Model]:::red

        L --> U[Error Analysis]
        M --> U
        P --> U

        U --> V[Prompt Iteration]
        V --> B

        U --> W[Context Enhancement]
        W --> HA

        U --> X[Model Fine-tuning]
        X --> D
    end

    subgraph VD[Vector Database Components]
        Y["**Embedding params** (dimensions, chunk/window size, overlap)"]:::yellow
        AF[Embedding model variants]
        AA["**Indexing** (M, ef_construction,ef_search)"]:::yellow
        Y --> Z[ElasticSearch or pgVector]
        AF --> Z
	      AA --> Z
    end

    subgraph "Monitoring"
        J --> AB[Langfuse Tracing]
        AB --> AC[Performance Metrics]
        AC --> AD[Cost Analysis]
        AD --> AE[Quality Scores - precision, faithfulness, factuality]:::yellow
        AE --> K
    end

    T --> D
    V -.-> C
    RP -.- VD
		classDef yellow fill:#D4C5A0,color:#000000
		classDef green fill:#D4E7D4,color:#000000
		classDef red fill:#E7D4D4,color:#000000
